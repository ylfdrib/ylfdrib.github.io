#决策树损失函数
决策树剪枝，会用到正则化后的损失函数：
$$
C_{\alpha}(T)=\sum_{t=1}^{|T|} N_{t} H_{t}(T)+a|T|
$$
其中，$$|T|$$代表叶子节点个数，$$N_t$$表示具体某个叶子节点t的样例数，$$H_t(T)$$表示叶子节点的熵(用信息增益做分类)。
前一项$$\sum_{t=1}^{|T|} N_{t} H_{t}(T)$$是经验误差，概率模型中经验误差往往通过将极大似然取反，即将求极大化转为求极小化而获得。
$$
\sum_{t=1}^{|T|} N_{t} H_{t}(T)=-\sum_{t=1}^{|T|} \sum_{k=1}^{K} N_{t} \frac{N_{t k}}{N_{t}} \log \frac{N_{t k}}{N_{t}}=-\sum_{t=1}^{|T|} \sum_{k=1}^{K} N_{t k} \log \frac{N_{t k}}{N_{t}}=-\log \prod_{t=1}^{|T|}\left(\frac{N_{t k}}{N_{t}}\right)^{N_{t k}}
$$
其中，$$N_{tk}$$表示叶节点中t中，类别为k的样本数，$$K$$表示样例类别总数。
去掉负号，可得到对数极大似然函数：
$$
L(T)=\log \prod_{t=1}^{|T|} \prod_{k=1}^{K}\left(\frac{N_{t k}}{N_{t}}\right)^{N_{t k}}
$$
对应的极大似然函数：
$$
L(T)=\prod_{t=1}^{|T|} \prod_{k=1}^{K}\left(\frac{N_{t k}}{N_{t}}\right)^{N_{t k}}
$$
决策树的极大似然理解：先对各个叶节点之间进行极大似然估计，然后对各叶节点内部进行极大似然估计，由此得到整个决策树模型的极大似然函数。
